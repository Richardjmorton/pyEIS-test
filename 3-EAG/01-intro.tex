
\chapter{Introduction}

\newthought{The EUV Imaging Spectrometer} --- EIS\sidenote{EIS is part of the Hinode mission and
  was sponsored by the Japan Aerospace Exploration Agency (JAXA), the United Kingdom Space Agency
  (UKSA), and National Aeronautics and Space Administration (NASA) with contributions from ESA and
  Norway. Hinode was launched on September 22, 2006 at 21:36 UTC from the Uchinoura Space Center in
  Japan and continues to operate.} --- was designed to study the solar atmosphere and answer
fundamental questions on the heating of the solar corona, the origin of the solar wind, and the
release of energy in solar flares. EIS observes two wavelength ranges in the extreme ultraviolet,
171–-212\,\AA\ and 245–-291\,\AA\ with a spectral resolution of about 22\,m\AA\ and a plate scale
of 1\arcsec\ per pixel. Solar images can be made by stepping the slit over a region of the Sun and
taking an exposure at each position. A detailed description of EIS is given in the instrument
paper\cite{Culhane:2007}.

This document describes the basic elements of EIS data analysis using new HDF5 level-1 files and
new routines written in the Python programming language. At the beginning of the Hinode mission the
strategy was to release unprocessed level-0 FITS files and software routines written in IDL for
processing these files into a format that could be used for data analysis. Additionally, all of
the routines for computing ancillary information, such as the offsets of the detectors or the magnitude
of the instrumental broadening, were all written in IDL. Unfortunately, IDL is an expensive,
proprietary language, little used outside of solar physics. Python, in contrast, is a free, open
source language that has grown dramatically in popularity since the launch of Hinode, making it an
obvious choice for future software development.

To accelerate the transition to Python we have created a new level-1 product that contains both the
processed level-1 data and the ancillary information needed for data analysis. The alternative
approach, to port all of the existing IDL software to Python, would be time consuming and create
confusion about which routines are being actively supported during the transition. Distributing
level-1 files removes this problem, but does make the user dependent on the team for reformatting
all of the files as bugs are discovered. Since the mission has been going on for some time now, the
number of bugs is likely to be small.

There are several other design decisions that merit some explanation

\begin{itemize}
  \item The data and header information are stored in separate files. Since the data is large and
    unlikely to change, the time-consuming download of these files should only need to be done
    once. The header file is very small and can be updated easily.
  \item HDF5 is used to store the data. This is a very widely used, high-performance file format
    that is well supported by both IDL and Python. The most attractive feature for this application
    is that data is stored in a self-documenting, directory-like tree structure instead of binary
    table extensions.
  \item The data is processed from raw ``data numbers'' to ``photon events'' or ``counts''. The
    default behavior of \verb+eis_prep+ is to convert to calibrated units. With the HDF5 files
    conversion to absolute units is done using a calibration curve in the header file, and several
    different calibration curves can be considered.
\end{itemize}

The remaining chapters of this document describe the contents of the level-1 files and illustrate
how to use these files for data analysis in Python.
